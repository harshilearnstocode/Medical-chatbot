{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16w2KFW2T3l0",
        "outputId": "56705f13-2613-4f33-8b13-da3bf727e11a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Downloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "Vl7hXEt3T7FG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "print(\"✅ API key set successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rjh2S7tUESa",
        "outputId": "ac687ae7-7afc-4066-daa0-8f1fd5ae77ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key: ··········\n",
            "✅ API key set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symptom_to_disease = {\n",
        "    \"chest pain\": [\"Angina\", \"Heart Attack\"],\n",
        "    \"rash\": [\"Eczema\", \"Allergic Reaction\"],\n",
        "    \"fever\": [\"Flu\", \"Infection\"]\n",
        "}\n",
        "\n",
        "disease_to_department = {\n",
        "    \"Angina\": \"Cardiology\",\n",
        "    \"Heart Attack\": \"Cardiology\",\n",
        "    \"Eczema\": \"Dermatology\",\n",
        "    \"Allergic Reaction\": \"Dermatology\",\n",
        "    \"Flu\": \"General Medicine\",\n",
        "    \"Infection\": \"General Medicine\"\n",
        "}\n",
        "\n",
        "def map_symptoms_to_department(symptom_text: str):\n",
        "    matched = []\n",
        "    for symptom, diseases in symptom_to_disease.items():\n",
        "        if symptom in symptom_text.lower():\n",
        "            for disease in diseases:\n",
        "                department = disease_to_department.get(disease, \"General Medicine\")\n",
        "                matched.append((disease, department))\n",
        "    return matched\n"
      ],
      "metadata": {
        "id": "m5RLKSgPUNYc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt4o_medical_advice(state):\n",
        "    messages = state[\"messages\"]\n",
        "    user_input = messages[-1][\"content\"].strip().lower()\n",
        "\n",
        "    full_convo = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages[-5:]])  # last 5 turns\n",
        "\n",
        "    if any(greet in user_input for greet in [\"hello\", \"hi\", \"hey\"]):\n",
        "        reply = \"👋 Hello! I'm a medical assistant. You can tell me your symptoms, and I’ll guide you to the right department.\"\n",
        "\n",
        "    elif \"what to do\" in user_input or \"what should i do\" in user_input:\n",
        "        reply = (\n",
        "            \"Of course! Based on what you've shared so far, let me assess the symptoms.\\n\"\n",
        "            \"Please hold on...\"\n",
        "        )\n",
        "        system_prompt = (\n",
        "            \"You are a helpful medical assistant. The following is a conversation with a patient. \"\n",
        "            \"Based on the recent messages, infer what condition the patient might be experiencing and \"\n",
        "            \"suggest which medical department they should consult. Use short, helpful responses.\"\n",
        "        )\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": full_convo}\n",
        "            ],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        reply = response.choices[0].message.content\n",
        "\n",
        "    else:\n",
        "        system_prompt = (\n",
        "            \"You are a medical assistant. Given a symptom description from a user, \"\n",
        "            \"infer possible causes and suggest which department to consult. \"\n",
        "            \"Keep responses short, professional, and clear.\"\n",
        "        )\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ],\n",
        "            temperature=0.4\n",
        "        )\n",
        "\n",
        "        reply = response.choices[0].message.content\n",
        "\n",
        "    return {\n",
        "        \"messages\": messages + [{\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": reply\n",
        "        }]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "th3SYSwEUPaI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Dict, Any\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    messages: List[Dict[str, Any]]\n",
        "\n",
        "graph = StateGraph(ChatState)\n",
        "\n",
        "graph.add_node(\"GPT-4o\", gpt4o_medical_advice)\n",
        "\n",
        "graph.set_entry_point(\"GPT-4o\")\n",
        "graph.set_finish_point(\"GPT-4o\")\n",
        "\n",
        "lang_graph = graph.compile()\n"
      ],
      "metadata": {
        "id": "GnYsnrFoUSkH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_interface():\n",
        "    print(\"🩺 Medical Chatbot: Type your symptoms (or 'exit')\")\n",
        "    state = {\"messages\": []}\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"👋 Take care!\")\n",
        "            break\n",
        "        state['messages'].append({\"role\": \"user\", \"content\": user_input})\n",
        "        state = lang_graph.invoke(state)\n",
        "        print(\"Bot:\", state['messages'][-1]['content'])\n",
        "\n",
        "chat_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzp_Q0eUVT3",
        "outputId": "99112e6e-4641-4119-ee1f-4afcd9c95654"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🩺 Medical Chatbot: Type your symptoms (or 'exit')\n",
            "You: Hello\n",
            "Bot: 👋 Hello! I'm a medical assistant. You can tell me your symptoms, and I’ll guide you to the right department.\n",
            "You: I ahve head ache\n",
            "Bot: Headaches can have various causes, including tension, migraines, dehydration, stress, or sinus issues. It is advisable to consult with a General Practitioner (GP) to determine the underlying cause and appropriate treatment. If the headache is severe, persistent, or accompanied by other symptoms like vision changes or nausea, seek medical attention promptly.\n",
            "You: what to do\n",
            "Bot: For now, you can try resting in a quiet, dark room and applying a cold or warm compress to your head. Stay hydrated by drinking water, and consider over-the-counter pain relief like ibuprofen or acetaminophen if you can take them safely. However, it's important to consult with a General Practitioner (GP) to identify the cause of your headache and receive appropriate treatment.\n",
            "You: what should I eat\n",
            "Bot: If you're seeking general dietary advice, it's best to consult with a nutritionist or dietitian who can provide personalized recommendations based on your health needs and goals. If you have specific symptoms or health concerns, please provide more details so I can guide you to the appropriate department.\n",
            "You: exit\n",
            "👋 Take care!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KbfwK7eUtA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}